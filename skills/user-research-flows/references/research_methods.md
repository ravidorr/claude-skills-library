# Research Methods Reference

Comprehensive guide to user research methodologies for enterprise, B2B, and technical products. Reference when planning or conducting user research.

## Why User Research Matters

**Purpose**:

- Understand real user needs
- Validate assumptions
- Reduce risk of building wrong thing
- Inform design decisions
- Measure success

**Research vs. Assumptions**:

- Research: Based on observation and data
- Assumptions: Based on beliefs and guesses
- Both have a place, but know which is which

## Research Types

### Qualitative Research

**Goal**: Understand why and how

**Methods**:

- User interviews
- Observational studies
- Usability testing
- Diary studies
- Field studies

**Output**:

- Insights, themes, patterns
- Quotes, stories
- Pain points, needs
- Mental models

**When to Use**:

- Early exploration
- Understanding context
- Discovering problems
- Generating ideas

### Quantitative Research

**Goal**: Measure what and how much

**Methods**:

- Surveys
- Analytics
- A/B testing
- Metrics analysis
- Heatmaps

**Output**:

- Numbers, percentages
- Statistical significance
- Trends over time
- Comparisons

**When to Use**:

- Validate hypotheses
- Measure behavior
- Prioritize features
- Track improvements

### Generative Research

**Goal**: Explore and discover

**Focus**: "What should we build?"

**Methods**:

- Exploratory interviews
- Ethnographic research
- Diary studies
- Open-ended surveys

**Outcome**:

- Problem identification
- Opportunity areas
- User needs
- Unmet desires

**Phase**: Early/discovery

### Evaluative Research

**Goal**: Test and validate

**Focus**: "Did we build it right?"

**Methods**:

- Usability testing
- Prototype testing
- A/B testing
- Surveys (satisfaction)

**Outcome**:

- Usability issues
- Preference data
- Success metrics
- Improvements needed

**Phase**: Design/post-launch

## Research Methods for Enterprise/B2B

### User Interviews

**Best For**:

- Understanding needs, goals, pain points
- Exploring workflows
- Building personas
- Validating assumptions

**Structure**:

- 30-60 minutes
- 1-on-1 or small group
- Semi-structured (script + flexibility)
- Record (with permission)

**Interview Guide Template**:

```text
Introduction (5 min)
- Explain purpose
- Request permission to record
- Establish rapport

Background (10 min)
- Role and responsibilities
- Team structure
- Daily workflow
- Tools currently used

Current State (15-20 min)
- Walk through typical day
- Describe recent task
- Pain points and frustrations
- Workarounds developed

Future State (10 min)
- Ideal solution
- Must-have vs. nice-to-have
- Willingness to change

Wrap-up (5 min)
- Additional thoughts
- Thank you
- Next steps
```

**Question Types**:

**Open-Ended** (preferred):

- "Tell me about..."
- "Walk me through..."
- "What happens when..."
- "How do you currently..."

**Follow-Up Probes**:

- "Can you give me an example?"
- "What do you mean by that?"
- "How did that make you feel?"
- "What happened next?"

**Avoid**:

- Leading questions: "Don't you think...?"
- Yes/no questions: "Do you like...?"
- Multiple questions: "How do you X and do you Y and what about Z?"

**Participant Recruitment**:

**Existing Customers**:

- Reach out via email
- Offer incentive (gift card, feature priority)
- Use CS/Sales relationships
- Track in CRM

**Prospects**:

- Recruit through sales team
- Attend industry events
- LinkedIn outreach
- User groups

**Internal Stakeholders**:

- Sales (what customers ask for)
- Support (common problems)
- CS (power user insights)
- Engineering (technical constraints)

### Observational Studies

**Best For**:

- Understanding actual behavior (not reported)
- Discovering pain points users don't articulate
- Seeing workflow in context
- Finding inefficiencies

**Types**:

**Contextual Inquiry**:

- Visit user in their environment
- Observe them working
- Ask questions as they work
- Master/apprentice relationship

**Remote Observation**:

- Screen sharing
- Watch them use product
- Think-aloud protocol
- Record for later analysis

**Field Study**:

- Extended observation (days/weeks)
- Immerse in user environment
- Understand full context
- Deep insights

**Process**:

1. **Prepare**: Define what to observe, create framework
2. **Observe**: Watch, take notes, minimal interruption
3. **Interview**: Ask questions after tasks
4. **Document**: Photos (if allowed), diagrams, quotes
5. **Synthesize**: Find patterns, identify insights

**What to Observe**:

- Physical environment
- Tools and artifacts used
- Interruptions and context switches
- Workarounds and hacks
- Collaboration patterns
- Emotional reactions
- Time spent on tasks

### Usability Testing

**Best For**:

- Finding usability issues
- Validating designs
- Comparing alternatives
- Measuring task success

**Setup**:

- 5-8 participants (enough to find major issues)
- Realistic tasks
- Think-aloud protocol
- Record screen and audio

**Task Design**:

**Good Task**:

- Realistic scenario
- Clear goal, not specific steps
- Example: "You need to find out why the API response time increased. What would you do?"

**Bad Task**:

- Step-by-step instructions
- Example: "Click on Dashboard, then click Metrics, then..."

**Metrics to Collect**:

- Task success rate (%)
- Time to complete
- Error rate
- Subjective satisfaction (1-7 scale)
- Quotes and observations

**Analysis**:

- Categorize issues by severity
- Identify patterns across participants
- Create prioritized list
- Recommend fixes

### Surveys

**Best For**:

- Collecting data from many users
- Validating findings
- Measuring satisfaction
- Prioritizing features

**When to Use**:

- After launch (feedback)
- Research validation (confirm hypotheses)
- Feature prioritization (vote on roadmap)
- Segmentation (understand user types)

**Question Types**:

**Rating Scales**:

- Likert (1-5 or 1-7): "How satisfied are you..."
- NPS (0-10): "How likely to recommend..."
- Agree/Disagree: "The system is easy to use"

**Multiple Choice**:

- Single select
- Multi-select
- Ranking

**Open-Ended**:

- Short answer
- Long response

**Survey Best Practices**:

- Keep short (5-10 min)
- Start with screening questions
- Group related questions
- One question per item
- Avoid jargon
- Provide "Other" option
- Test survey first
- Offer incentive (for longer surveys)

**Sample Survey Structure**:

```text
Introduction
- Purpose of survey
- Time estimate
- Thank you

Screening (if needed)
- Do you currently use [product]?
- What is your role?

Core Questions
- [Specific questions for your research]

Demographics (if needed)
- Role
- Company size
- Industry

Thank You
- What happens next
- Contact info (if needed)
```

### Analytics Analysis

**Best For**:

- Understanding actual behavior
- Identifying drop-off points
- Measuring feature usage
- Tracking trends over time

**Key Metrics**:

**Engagement**:

- Daily/Weekly/Monthly Active Users
- Session duration
- Feature usage frequency
- Return rate

**Adoption**:

- Time to first value
- Feature adoption rate
- Setup completion rate
- Integration connections

**Retention**:

- Churn rate
- User lifecycle
- Cohort analysis
- Resurrection rate

**Performance**:

- Task completion rate
- Error rates
- Support tickets
- Page load times

**Analysis Approaches**:

**Funnel Analysis**:

- Map critical user journeys
- Identify drop-off points
- Calculate conversion rates
- Prioritize improvements

**Cohort Analysis**:

- Group users by signup date
- Track behavior over time
- Identify trends
- Measure improvements

**Path Analysis**:

- How users navigate
- Common paths vs. expected
- Where users get stuck
- Optimization opportunities

### Diary Studies

**Best For**:

- Understanding long-term behavior
- Capturing in-the-moment experiences
- Studying sporadic events
- Longitudinal insights

**Structure**:

- 1-4 weeks duration
- Daily or triggered entries
- Text, photos, videos
- Periodic check-ins

**Example Diary Prompts**:

- "Describe a time today when you encountered [problem]"
- "What was the most frustrating part of your day?"
- "Share a photo of your workspace right now"

**Tools**:

- Email journals
- SMS/WhatsApp
- Dedicated diary apps (dscout, Indeemo)
- Shared documents

### Competitive Analysis

**Best For**:

- Understanding market standards
- Finding opportunities
- Benchmarking features
- Avoiding mistakes

**What to Analyze**:

- Core features
- User flows
- Pricing models
- Positioning
- Strengths/weaknesses

**Process**:

- Identify competitors (direct and indirect)
- Sign up for trials
- Complete key tasks
- Document with screenshots
- Compare feature matrices

## Research Planning

### Research Question Framework

**Good Research Questions**:

- Specific and focused
- Answerable with available methods
- Actionable (will inform decisions)

**Example Good Questions**:

- "What are the top 3 pain points for DevOps engineers using our monitoring tool?"
- "How do users currently troubleshoot API errors?"
- "What would make users upgrade from free to paid?"

**Example Poor Questions**:

- "What do users want?" (too broad)
- "Is our product good?" (not actionable)
- "Should we build feature X?" (yes/no, not exploratory)

### Research Plan Template

```markdown
# Research Plan: [Topic]

## Background
- Why are we doing this research?
- What decisions will it inform?
- What do we already know?

## Research Questions
1. [Primary question]
2. [Secondary question]
3. [Secondary question]

## Methodology
- **Method**: [Interview / Usability Test / Survey / etc.]
- **Participants**: [Who, how many]
- **Duration**: [How long]
- **Timeline**: [When]

## Recruitment
- **Criteria**: [Who to include/exclude]
- **Source**: [Where to find them]
- **Incentive**: [Compensation]

## Script/Guide
[Attach interview guide, tasks, survey questions]

## Analysis Plan
- What data will we collect?
- How will we analyze it?
- What format for deliverables?

## Team
- Researcher: [Name]
- Note-taker: [Name]
- Observers: [Names]

## Success Criteria
- X participants completed
- Key questions answered
- Actionable insights generated
```

## Research Synthesis

### Note-Taking During Research

**Structure**:

- Timestamp
- Observation or quote
- Your interpretation
- Questions raised

**Example**:

```text
[14:23] 
Observation: User opened three different tabs to find API documentation
Interpretation: Information architecture may not be clear
Question: Is this common? What would make it easier?
```

### Analysis Process

**Step 1: Organize Data**

- Transcribe interviews (or key parts)
- Compile notes
- Gather artifacts (screenshots, photos)

**Step 2: Find Patterns**

- Read through all data
- Highlight interesting quotes
- Note recurring themes
- Look for contradictions

**Step 3: Synthesize Insights**

- What did we learn?
- What surprised us?
- What was confirmed?
- What's still unclear?

**Step 4: Recommend Actions**

- Prioritize findings
- Suggest solutions
- Link to business goals

### Insight Template

```text
**Finding**: [What we observed]
**Evidence**: [Quotes, data points]
**Implication**: [What it means for design]
**Recommendation**: [What we should do]
**Priority**: [Critical / High / Medium / Low]
```

### Research Deliverables

**Readout Presentation** (for stakeholders):

- Executive summary
- Key findings (3-5)
- Supporting evidence
- Recommendations
- Next steps

**Detailed Report** (for team):

- Full methodology
- All findings
- Raw data (appendix)
- Personas/journeys

**Quick Share** (ongoing project):

- Slack update with top 3 learnings
- Short video highlights
- Shared notes document

## Research Ethics

### Informed Consent

**What to Explain**:

- Purpose of research
- How data will be used
- Recording (if applicable)
- Privacy protections
- Right to stop anytime

**Get Written Consent For**:

- Recording (audio/video)
- Sharing quotes
- Screenshots/photos
- Using in case studies

### Privacy & Data Protection

**Best Practices**:

- Anonymize participants
- Secure data storage
- Limited access
- Delete after project (or set retention)
- Comply with GDPR/regulations

### Recruiting Ethics

**Fair Compensation**:

- Pay for people's time
- Industry standard: $50-100/hour
- Gift cards or cash
- Don't exploit relationships

**Representative Sampling**:

- Don't only talk to fans
- Include diverse perspectives
- Seek critical feedback

## Enterprise/B2B Research Challenges

### Challenge 1: Access to Users

**Problem**: Hard to reach busy professionals

**Solutions**:

- Work with CS/Sales for intros
- Offer executive summaries
- Make it worth their time
- Be flexible on scheduling
- Go to them (not vice versa)

### Challenge 2: Long Sales Cycles

**Problem**: Takes months to get customers

**Solutions**:

- Research with prospects
- Use competitive products
- Talk to churned customers
- Internal proxy users (sales, support)

### Challenge 3: Technical Complexity

**Problem**: Products are complex

**Solutions**:

- Learn the domain
- Get technical help
- Focus on goals, not implementation
- Use realistic tasks

### Challenge 4: Multiple Stakeholders

**Problem**: Many people influence decision

**Solutions**:

- Map stakeholders
- Interview different roles
- Understand buying process
- Design for each persona

## Research Resources

### Tools

- **User Interviews**: Respondent, UserTesting
- **Surveys**: Typeform, Google Forms, Qualtrics
- **Analytics**: Mixpanel, Amplitude, Heap
- **Note-Taking**: Notion, Dovetail, EnjoyHQ
- **Synthesis**: Miro, Figjam, Dovetail

### Books

- "Just Enough Research" by Erika Hall
- "Interviewing Users" by Steve Portigal
- "The Mom Test" by Rob Fitzpatrick
- "Lean UX" by Jeff Gothelf
- "User Research" by Stephanie Marsh

### Online Resources

- Nielsen Norman Group: <https://www.nngroup.com/>
- UXPA: <https://uxpa.org/>
- ResearchOps Community: <https://researchops.community/>
